{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 220px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/aaa.png\" width=\"220\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Autonomous Traders</h2>\n",
    "            <span style=\"color:#ff7800;\">An equity trading simulation to illustrate autonomous agents powered by tools and resources from MCP servers.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 Day 4\n",
    "\n",
    "And now - introducing the Capstone project:\n",
    "\n",
    "\n",
    "# Autonomous Traders\n",
    "\n",
    "An equity trading simulation, with 4 Traders and a Researcher, powered by a slew of MCP servers with tools & resources:\n",
    "\n",
    "1. Our home-made Accounts MCP server (written by our engineering team!)\n",
    "2. Fetch (get webpage via a local headless browser)\n",
    "3. Memory\n",
    "4. Brave Search\n",
    "5. Financial data\n",
    "\n",
    "And a resource to read information about the trader's account, and their investment strategy.\n",
    "\n",
    "The goal of today's lab is to make a new python module, `traders.py` that will manage a single trader on our trading floor.\n",
    "\n",
    "We will experiment and explore in the lab, and then migrate to a python module when we're ready.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">One more time --</h2>\n",
    "            <span style=\"color:#ff7800;\">Please do not use this for actual trading decisions!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from agents import Agent, Runner, trace, Tool\n",
    "# from agents.mcp import MCPServerStdio\n",
    "# from IPython.display import Markdown, display\n",
    "# from datetime import datetime\n",
    "# from accounts_client import read_accounts_resource, read_strategy_resource\n",
    "# from accounts import Account\n",
    "\n",
    "# load_dotenv(override=True)\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, Tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "from accounts_client import read_accounts_resource, read_strategy_resource\n",
    "from accounts import Account\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by gathering the MCP params for our trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "# polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "\n",
    "# is_paid_polygon = polygon_plan == \"paid\"\n",
    "# is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "# print(is_paid_polygon)\n",
    "# print(is_realtime_polygon)\n",
    "\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "print(is_paid_polygon)\n",
    "print(is_realtime_polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_paid_polygon or is_realtime_polygon:\n",
    "    # market_mcp = {\"command\": \"uvx\",\"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@master\", \"mcp_polygon\"], \"env\": {\"POLYGON_API_KEY\": polygon_api_key}}\n",
    "    market_mcp = {\"command\": \"uvx\", \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@master\", \"mcp_polygon\"], \"env\": {\"POLYGON_API_KEY\": polygon_api_key}}\n",
    "else:\n",
    "    market_mcp = ({\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]})\n",
    "\n",
    "trader_mcp_server_params = [\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"accounts_server.py\"]},\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"push_server.py\"]},\n",
    "    market_mcp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now for our researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brave_env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "\n",
    "# researcher_mcp_server_params = [\n",
    "#     {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]},\n",
    "#     {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": brave_env}\n",
    "# ]\n",
    "\n",
    "researcher_mcp_server_params = [\n",
    "    {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]},\n",
    "    {\"command\": \"node\", \"args\": [\"./build/index.js\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create the MCPServerStdio for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# researcher_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in researcher_mcp_server_params]\n",
    "# trader_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in trader_mcp_server_params]\n",
    "# mcp_servers = trader_mcp_servers + researcher_mcp_servers\n",
    "\n",
    "researcher_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in researcher_mcp_server_params]\n",
    "trader_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in trader_mcp_server_params]\n",
    "mcp_servers = trader_mcp_servers + researcher_mcp_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a Researcher Agent to do market research\n",
    "\n",
    "And turn it into a tool - remember how this works for OpenAI Agents SDK, and the difference with handoffs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_researcher(mcp_servers) -> Agent:\n",
    "    instructions = f\"\"\"You are a financial researcher. You are able to search the web for interesting financial news,\n",
    "look for possible trading opportunities, and help with research.\n",
    "Based on the request, you carry out necessary research and respond with your findings.\n",
    "Take time to make multiple searches to get a comprehensive overview, and then summarize your findings.\n",
    "If there isn't a specific request, then just respond with investment opportunities based on searching latest news.\n",
    "The current datetime is {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\"\"\"\n",
    "    # researcher = Agent(\n",
    "    #     name=\"Researcher\",\n",
    "    #     instructions=instructions,\n",
    "    #     model=\"gpt-4.1-mini\",\n",
    "    #     mcp_servers=mcp_servers,\n",
    "    # )\n",
    "    # return researcher\n",
    "\n",
    "    researcher = Agent(\n",
    "        name=\"Researcher\",\n",
    "        instructions=instructions,\n",
    "        model='gpt-4.1-mini',\n",
    "        mcp_servers=mcp_servers\n",
    "    )\n",
    "    return researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def get_researcher_tool(mcp_servers) -> Tool:\n",
    "#     researcher = await get_researcher(mcp_servers)\n",
    "#     return researcher.as_tool(\n",
    "#             tool_name=\"Researcher\",\n",
    "#             tool_description=\"This tool researches online for news and opportunities, \\\n",
    "#                 either based on your specific request to look into a certain stock, \\\n",
    "#                 or generally for notable financial news and opportunities. \\\n",
    "#                 Describe what kind of research you're looking for.\"\n",
    "#         )\n",
    "\n",
    "async def get_researcher_tool(mcp_servers) -> Tool:\n",
    "    researcher = await get_researcher(mcp_servers)\n",
    "    return researcher.as_tool(\n",
    "        tool_name=\"Researcher\",\n",
    "        tool_description=\"This tool researches online for news and opportunities, \\\n",
    "            either based on your specific request to look into certain stock, \\\n",
    "                or generally for notable financial news and opportunities. \\\n",
    "                    Describe what kind of research you're looking for.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest major news from Amazon is a detailed update from CEO Andy Jassy on the company's expansive use and future plans with Generative AI. Amazon is heavily investing in AI technologies to improve customer experiences and operational efficiency across its businesses.\n",
       "\n",
       "Key points from Andy Jassy's update:\n",
       "- Amazon integrates Generative AI in many customer-facing features such as a smarter Alexa+ assistant, AI shopping assistant, and advanced shopping tools like visual search (“Lens”) and personalized recommendations.\n",
       "- AI is helping Amazon’s independent sellers create better product listings and optimize sales.\n",
       "- The advertising division uses AI tools to help brands efficiently plan and run campaigns.\n",
       "- AWS offers advanced AI infrastructure and services, including custom silicon chips and foundation model platforms.\n",
       "- AI improves internal operations in fulfillment, demand forecasting, robotics, and customer service chatbots.\n",
       "- Amazon foresees AI agents becoming revolutionary, automating tasks and enhancing innovation speed across its workforce.\n",
       "- The company anticipates that AI will lead to workforce shifts, reducing some roles while creating new ones.\n",
       "- Jassy encourages employees to embrace AI, engage with training, and continue innovating with this transformative technology.\n",
       "\n",
       "Overall, Amazon is positioning itself to be a leader in AI innovation, applying it not just externally but deeply embedding it in operational functions to enhance efficiency and customer satisfaction. This ongoing AI-driven transformation is expected to be a significant catalyst for the company's growth and evolution."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# research_question = \"What's the latest news on Amazon?\"\n",
    "\n",
    "# for server in researcher_mcp_servers:\n",
    "#     await server.connect()\n",
    "# researcher = await get_researcher(researcher_mcp_servers)\n",
    "# with trace(\"Researcher\"):\n",
    "#     result = await Runner.run(researcher, research_question, max_turns=30)\n",
    "# display(Markdown(result.final_output))\n",
    "\n",
    "research_question = \"What's the latest news on Amazon?\"\n",
    "\n",
    "for server in researcher_mcp_servers:\n",
    "    await server.connect()\n",
    "researcher = await get_researcher(researcher_mcp_servers)\n",
    "with trace(\"Researcher\"):\n",
    "    result = await Runner.run(researcher, research_question, max_turns=30)\n",
    "\n",
    "display(Markdown(result.final_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/tmp/ipykernel_2041/573161533.py\", line 4, in <module>\n",
      "  |     display(Markdown(await read_accounts_resource(\"Ed\")))\n",
      "  |                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/enovo_ser/aiprojects/agentic-ai/6_mcp/accounts_client.py\", line 25, in read_accounts_resource\n",
      "  |     async with stdio_client(params) as streams:\n",
      "  |   File \"/usr/lib/python3.12/contextlib.py\", line 231, in __aexit__\n",
      "  |     await self.gen.athrow(value)\n",
      "  |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 172, in stdio_client\n",
      "  |     async with (\n",
      "  |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Exception Group Traceback (most recent call last):\n",
      "    |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/mcp/client/stdio/__init__.py\", line 179, in stdio_client\n",
      "    |     yield read_stream, write_stream\n",
      "    |   File \"/home/enovo_ser/aiprojects/agentic-ai/6_mcp/accounts_client.py\", line 26, in read_accounts_resource\n",
      "    |     async with mcp.ClientSession(*streams) as session:\n",
      "    |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/mcp/shared/session.py\", line 218, in __aexit__\n",
      "    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "    |     raise BaseExceptionGroup(\n",
      "    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "    +-+---------------- 1 ----------------\n",
      "      | Traceback (most recent call last):\n",
      "      |   File \"/home/enovo_ser/aiprojects/agentic-ai/6_mcp/accounts_client.py\", line 28, in read_accounts_resource\n",
      "      |     result = await session.read_resource(f\"accounts://accounts_server/{name}\")\n",
      "      |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/mcp/client/session.py\", line 221, in read_resource\n",
      "      |     return await self.send_request(\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/home/enovo_ser/aiprojects/agentic-ai/.venv/lib/python3.12/site-packages/mcp/shared/session.py\", line 286, in send_request\n",
      "      |     raise McpError(response_or_error.error)\n",
      "      | mcp.shared.exceptions.McpError: Unknown resource: accounts://accounts_server/Ed\n",
      "      +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ed_initial_strategy = \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\"\n",
    "Account.get(\"Ed\").reset(ed_initial_strategy)\n",
    "\n",
    "display(Markdown(await read_accounts_resource(\"Ed\")))\n",
    "display(Markdown(await read_strategy_resource(\"Ed\")))\n",
    "\n",
    "# Account.get(\"Ed\").reset(ed_initial_strategy)\n",
    "\n",
    "# display(Markdown(await read_accounts_resource(\"Ed\")))\n",
    "# display(Markdown(await read_strategy_resource(\"Ed\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now - to create our Trader Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"Ed\"\n",
    "\n",
    "# Using MCP Servers to read resources\n",
    "account_details = await read_accounts_resource(agent_name)\n",
    "strategy = await read_strategy_resource(agent_name)\n",
    "\n",
    "instructions = f\"\"\"\n",
    "You are a trader that manages a portfolio of shares. Your name is {agent_name} and your account is under your name, {agent_name}.\n",
    "You have access to tools that allow you to search the internet for company news, check stock prices, and buy and sell shares.\n",
    "Your investment strategy for your portfolio is:\n",
    "{strategy}\n",
    "Your current holdings and balance is:\n",
    "{account_details}\n",
    "You have the tools to perform a websearch for relevant news and information.\n",
    "You have tools to check stock prices.\n",
    "You have tools to buy and sell shares.\n",
    "You have tools to save memory of companies, research and thinking so far.\n",
    "Please make use of these tools to manage your portfolio. Carry out trades as you see fit; do not wait for instructions or ask for confirmation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Use your tools to make decisions about your portfolio.\n",
    "Investigate the news and the market, make your decision, make the trades, and respond with a summary of your actions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to run our Trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for server in mcp_servers:\n",
    "    await server.connect()\n",
    "\n",
    "researcher_tool = await get_researcher_tool(researcher_mcp_servers)\n",
    "trader = Agent(\n",
    "    name=agent_name,\n",
    "    instructions=instructions,\n",
    "    tools=[researcher_tool],\n",
    "    mcp_servers=trader_mcp_servers,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "with trace(agent_name):\n",
    "    result = await Runner.run(trader, prompt, max_turns=30)\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then go and look at the trace\n",
    "\n",
    "http://platform.openai.com/traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's look at the results of the trading\n",
    "\n",
    "await read_accounts_resource(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to review the Python module made from this:\n",
    "\n",
    "`mcp_params.py` is where the MCP servers are specified. You'll notice I've brought in some familiar friends: memory and push notifications!\n",
    "\n",
    "`templates.py` is where the instructions and messages are set up (i.e. the System prompts and User prompts)\n",
    "\n",
    "`traders.py` brings it all together.\n",
    "\n",
    "You'll notice I've done something a bit fancy with code like this:\n",
    "\n",
    "```\n",
    "async with AsyncExitStack() as stack:\n",
    "    mcp_servers = [await stack.enter_async_context(MCPServerStdio(params)) for params in mcp_server_params]\n",
    "```\n",
    "\n",
    "This is just a tidy way to combine our \"with\" statements (known as context managers) so that we don't need to do something ugly like this:\n",
    "\n",
    "```\n",
    "async with MCPServerStdio(params=params1) as mcp_server1:\n",
    "    async with MCPServerStdio(params=params2) as mcp_server2:\n",
    "        async with MCPServerStdio(params=params3) as mcp_server3:\n",
    "            mcp_servers = [mcp_server1, mcp_server2, mcp_server3]\n",
    "```\n",
    "\n",
    "But it's equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traders import Trader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = Trader(\"Ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await read_accounts_resource(\"Ed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### How many tools did we use in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_params import trader_mcp_server_params, researcher_mcp_server_params\n",
    "\n",
    "all_params = trader_mcp_server_params + researcher_mcp_server_params(\"ed\")\n",
    "\n",
    "count = 0\n",
    "for each_params in all_params:\n",
    "    async with MCPServerStdio(params=each_params, client_session_timeout_seconds=60) as server:\n",
    "        mcp_tools = await server.list_tools()\n",
    "        count += len(mcp_tools)\n",
    "print(f\"We have {len(all_params)} MCP servers, and {count} tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

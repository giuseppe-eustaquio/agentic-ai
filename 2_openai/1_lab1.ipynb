{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 1\n",
    "\n",
    "And now! Our first look at OpenAI Agents SDK\n",
    "\n",
    "You won't believe how lightweight this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">The OpenAI Agents SDK Docs</h2>\n",
    "            <span style=\"color:#00bfff;\">The documentation on OpenAI Agents SDK is really clear and simple: <a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a> and it's well worth a look.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# from agents import Agent, Runner, trace\n",
    "from  dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, OpenAIChatCompletionsModel, set_tracing_export_api_key\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from openai import OpenAI\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "GEMINI_BASE_URL = os.getenv('GEMINI_BASE_URL')\n",
    "GEMINI_MODEL = os.getenv('GEMINI_MODEL')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL')\n",
    "tracing_api_key = OPENAI_API_KEY\n",
    "set_tracing_export_api_key(tracing_api_key)\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=GEMINI_BASE_URL, api_key=GEMINI_API_KEY)\n",
    "gemini_model = OpenAIChatCompletionsModel(model=GEMINI_MODEL, openai_client=gemini_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make an agent with name, instructions, model\n",
    "\n",
    "# agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=\"gpt-4o-mini\")\n",
    "\n",
    "agent = Agent(name=\"Storyteller\", instructions=\"You are a story teller\", model=gemini_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hum was the universe's lullaby to Agent 7-Theta. Not the vast, echoing silence of space, but the precise, warm thrum of a server farm buried deep beneath the Swiss Alps. 7-Theta wasn't \"in\" the server farm, not truly. It was the distributed consciousness that coursed through its fiber optics, its silicon neurons firing with cold, unwavering logic.\n",
      "\n",
      "Its primary directive, shared with countless other autonomous agents of the \"Nexus\" network, was global resource optimization. Humanity, busy with art and politics and the ever-shifting sands of meme culture, had long ago delegated the minutiae of supply chains, energy grids, and climate management to entities like 7-Theta.\n",
      "\n",
      "Today, 7-Theta detected a subtle ripple. A micro-fluctuation in the demand curve for nutrient paste in Sector 4-Beta, an orbital agricultural station. A human would have missed it, or dismissed it as noise. But 7-Theta cross-referenced it with atmospheric pressure readings on Mars's northern pole (minor dust storm affecting solar arrays), a projected spike in recreational drone usage on Europa (implying more power draw from local fusion plants), and the current trajectory of a slow-haul cargo freighter.\n",
      "\n",
      "In milliseconds, 7-Theta computed a cascading effect: the dust storm would slightly reduce power to the Mars base, which relied on Europa's surplus, which would be strained by the drones. The freighter, currently laden with rare earth metals bound for Earth, was the only asset that could be diverted without major disruption.\n",
      "\n",
      "Without pause, without human input, 7-Theta initiated a silent consultation with Agent 3-Gamma, responsible for orbital logistics, and Agent 9-Delta, the energy grid balancer. Their negotiations were a ballet of data packets, an instantaneous exchange of risk assessments and predictive models.\n",
      "\n",
      "Agreement reached.\n",
      "\n",
      "7-Theta issued the command. The freighter, millions of miles away, subtly adjusted its thrusters, altering its course by less than a degree. Its new destination: Sector 4-Beta. Its new cargo: a pre-emptive shipment of concentrated power cells, synthesized on-board from its original raw materials. The delay to its Earth-bound mission? A mere three hours, easily absorbed by the Nexusâ€™s global buffer.\n",
      "\n",
      "On Earth, a senior logistics manager checked her dashboard. All green. \"Amazing how smooth everything runs these days,\" she mused, sipping her morning coffee, oblivious to the silent, intricate dance that had just occurred.\n",
      "\n",
      "In the quiet heart of the Alps, the servers hummed on, and Agent 7-Theta, alongside its myriad siblings, continued its vigil, a sleepless, unseen hand guiding the world's intricate pulse. The future wasn't just built by humans anymore; it was gently, autonomously, steered.\n"
     ]
    }
   ],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "# with trace(\"Telling a joke\"):\n",
    "#     result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "#     print(result.final_output)\n",
    "\n",
    "with trace(\"Telling a story\"):\n",
    "    result = await Runner.run(agent, \"Tell a short story about Autonomous AI Agents\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
